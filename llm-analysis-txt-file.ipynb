{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.55.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyMuPDF in /opt/anaconda3/lib/python3.11/site-packages (1.24.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.11/site-packages (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install PyMuPDF \n",
    "%pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "github_token = os.environ[\"GITHUB_KEY\"]\n",
    "if not github_token:\n",
    "    raise ValueError(\"GITHUB_TOKEN is not set in your system environment variables\")\n",
    "\n",
    "# Set the required OpenAI environment variables using the retrieved token\n",
    "os.environ[\"OPENAI_API_KEY\"] = github_token\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://models.inference.ai.azure.com/\"\n",
    "\n",
    "print(\"Environment variables have been set successfully.\")\n",
    "\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "@staticmethod\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def pdf_to_base64_images(pdf_path):\n",
    "    #Handles PDFs with multiple pages\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    base64_images = []\n",
    "    temp_image_paths = []\n",
    "\n",
    "    total_pages = len(pdf_document)\n",
    "\n",
    "    for page_num in range(total_pages):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.open(io.BytesIO(pix.tobytes()))\n",
    "        temp_image_path = f\"temp_page_{page_num}.png\"\n",
    "        img.save(temp_image_path, format=\"PNG\")\n",
    "        temp_image_paths.append(temp_image_path)\n",
    "        base64_image = encode_image(temp_image_path)\n",
    "        base64_images.append(base64_image)\n",
    "\n",
    "    for temp_image_path in temp_image_paths:\n",
    "        os.remove(temp_image_path)\n",
    "\n",
    "    return base64_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_page_data(base64_image):\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an OCR-like data extraction tool that extracts data from textbook PDFs.\n",
    "   \n",
    "    1. Please extract the data from this textbook page and output 5 sentences that describe the main points of this page. Do not number or bullet the sentences.\n",
    "\n",
    "    2. The text should only contain the sentences and no title.\n",
    "\n",
    "    3. If the page contains no relevant text data, please output an empty text object and don't make up any data.\n",
    "\n",
    "    4. If there are blank data fields in the invoice, please include them as \"null\" values in the text object.\n",
    "\n",
    "    5. Ignore tables and only pay attention to captions. If a page is only a table try to create a sentence summarizing the table.\n",
    "            \n",
    "    6. Don't interpolate or make up data.\n",
    "\n",
    "    7. If there is not enough text data to form 5 sentences that are distinct in meaning, you can choose to output less sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_format={ \"type\": \"text\" },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"extract the data in this textbook chapter and output into text \"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\", \"detail\": \"high\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PDF TO 5 SENTENCES \"\"\"\n",
    "\n",
    "def extract_from_multiple_pages(base64_images, original_filename, output_directory):\n",
    "    entire_invoice = []\n",
    "\n",
    "    for base64_image in base64_images:\n",
    "        # Extract data for each image\n",
    "        invoice_text = summarize_page_data(base64_image)\n",
    "        \n",
    "        # Since it's plain text, append it to the list\n",
    "        entire_invoice.append(invoice_text.strip())\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Construct the output file path\n",
    "    output_filename = os.path.join(output_directory, original_filename.replace('.pdf', '_extracted.txt'))\n",
    "    \n",
    "    # Save the entire_invoice list as a plain text file\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        for page_text in entire_invoice:\n",
    "            f.write(page_text + '\\n\\n')  # Separate pages with a double newline\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "def main_extract(read_path, write_path):\n",
    "    # to save tokens we will only do the first 3 invoices\n",
    "    for filename in os.listdir(read_path)[:3]:\n",
    "        file_path = os.path.join(read_path, filename)\n",
    "        print(f\"Extracting data from {file_path}\")\n",
    "        if os.path.isfile(file_path):\n",
    "            base64_images = pdf_to_base64_images(file_path)\n",
    "            extract_from_multiple_pages(base64_images, filename, write_path)\n",
    "\n",
    "read_path= \"./data/textdata\"\n",
    "write_path= \"./data/output\"\n",
    "\n",
    "main_extract(read_path, write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Function to summarize text using OpenAI's GPT API\n",
    "\n",
    "def summarize_text_file(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        text_data = file.read().strip()\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an OCR-like data extraction tool that extracts data from textbook PDFs.\n",
    "   \n",
    "    1. Please summarize the content and output 10 sentences that describe the main points. Do not number or bullet the sentences.\n",
    "\n",
    "    2. The text should only contain the sentences and no title.\n",
    "\n",
    "    3. If the text contains no relevant information, please output an empty text object and don't make up any data.\n",
    "\n",
    "    4. Ignore tables and focus only on meaningful captions or descriptive content.\n",
    "\n",
    "    5. Don't interpolate or make up data.\n",
    "\n",
    "    6. If there is not enough text data to form 10 sentences that are distinct in meaning, you can choose to output fewer sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_format={ \"type\": \"text\" },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"extract the data in this textbook chapter and output into text \"},\n",
    "                    {\"type\": \"text\", \"text\": f\"{text_data}\"}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    text = response.choices[0].message.content\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "\n",
    "# Main function to summarize all text files in a directory\n",
    "def summarize_all_files(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            input_file_path = os.path.join(input_dir, filename)\n",
    "            output_file_path = os.path.join(output_dir, filename.replace('.txt', '_summary.txt'))\n",
    "            summarize_text_file(input_file_path, output_file_path)\n",
    "\n",
    "# Paths for input and output directories\n",
    "input_directory = \"./data/output\"\n",
    "output_directory = \"./data/output_summary\"\n",
    "\n",
    "# Run the script\n",
    "summarize_all_files(input_directory, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
